
### Create haiku with default params
POST {{host}}/chat/llm/haiku?provider=DOCKER

> {%
    client.test("Status", function () {
        client.assert(response.status === 200, "Unexpected response status");
    });
%}

### Create haiku with params
POST {{host}}/chat/llm/haiku?provider=DOCKER&style=crazy&topic=Trump

> {%
    client.test("Status", function () {
        client.assert(response.status === 200, "Unexpected response status");
    });
%}

### Create llmCompletion from internal LLM like ollama with a fact
POST {{host}}/chat/llm
Content-Type: application/json

{
  "prompt": "I'm the president of France and my name is Macron",
  "style": "end answer with: Hope answer is correct!",
  "chat_id": "president-id",
  "llm_provider": "OLLAMA"
}

### invalid provider
POST {{host}}/chat/llm
Content-Type: application/json

{
  "prompt": "I'm the president of France and my name is Macron",
  "style": "end answer with: Hope answer is correct!",
  "chat_id": "president-id",
  "llm_provider": "PERPLEXITY"
}

### Create llmCompletion from internal LLM like ollama
POST {{host}}/chat/llm
Content-Type: application/json

{
  "prompt": "who am I",
  "style": "end answer with: Hope answer is correct!",
  "chat_id": "president-id",
  "llm_provider": "OLLAMA"
}

> {%
    client.test("Status", function () {
        client.assert(response.status === 200, "Unexpected response status");
    });
%}

### Create llmCompletion from external LLM Anthropic
POST {{host}}/chat/llm
Content-Type: application/json

{
  "prompt": "Are Trump and Musk still BFF friends",
  "style": "answer with max 10 word and end answer with Presently!",
  "llm_provider": "ANTHROPIC"
}

### Create llmCompletion from external LLM OpenAi/chatGpt
POST {{host}}/chat/llm
Content-Type: application/json

{
  "prompt": "Are Trump and Musk still best friends",
  "style": "answer with max 10 word and end answer with Presently!",
  "llm_provider": "OPENAI"
}

### Create llmCompletion using chat-id
POST {{host}}/chat/llm
Content-Type: application/json

{
  "prompt": "My name is Max and I'm the brother of Måns",
  "style": "end answer with: Got it!",
  "chat_id": "me-id",
  "llm_provider": "OPENAI"
}

### Create llmCompletion relating to previous question
POST {{host}}/chat/llm
Content-Type: application/json

{
  "prompt": "Tell everything about Måns",
  "style": "end answer with: I recall!",
  "chat_id": "me-id",
  "llm_provider": "OPENAI"
}

### Create llmCompletion relating to previous question with correction
POST {{host}}/chat/llm
Content-Type: application/json

{
  "prompt": "You forgot to mention that Måns has a brother Max",
  "style": "end answer with: I recall!",
  "chat_id": "me-id",
  "llm_provider": "OPENAI"
}

### Create llmCompletion with complex relations
POST {{host}}/chat/llm
Content-Type: application/json

{
  "prompt": "I, Tom, have a half brother Rick that has a half brother named John. How many brothers does John have",
  "style": "end answer with: Ok!",
  "llm_provider": "OPENAI"
}

### Create llmCompletion with correction
POST {{host}}/chat/llm
Content-Type: application/json

{
  "prompt": "Hope you understand the three different cases: 1. John and I have the same two parents. 2. John and I share one parent. 3. John and I have no parents in common.",
  "style": "end answer with: I got it!",
  "llm_provider": "OPENAI"
}

> {%
    client.test("Status", function () {
        client.assert(response.status === 200, "Unexpected response status");
    });
%}

### Create LLM llmCompletion from docker
POST {{host}}/chat/llm
Content-Type: application/json

{
  "prompt": "who is president in France",
  "style": "end answer with: Hope answer is ok!",
  "llm_provider": "DOCKER"
}

> {%
    client.test("Status", function () {
        client.assert(response.status === 200, "Unexpected response status");
    });
%}

### Create llmCompletion from all LLMs like ollama, docker, openai, anthropic
POST {{host}}/chat/llm/all
Content-Type: application/json

{
  "prompt": "Are Trump and Musk in the Epstein files",
  "style": "answer with max 10 word and end answer with Presently!"
}


### GET one or several completions from a given llmPrompt id
GET {{host}}/chat/prompt/1f3fa64a-295e-4085-9e4e-524583aeaa3f

### GET one or several completions from a given text in a previous prompt (case sensitive)
GET {{host}}/chat/prompt/contains/Epstein

### GET one or several interactions from a given text in a previous completion (case sensitive)
GET {{host}}/chat/completion/contains/Trump

### GET several completions from several llmPrompt with same chatId
GET {{host}}/chat/chat/ping-chat-service-status

### GET status of all LLMs
GET {{host}}/chat/status


### Info
GET {{host}}/actuator/info

### Prometheus
GET {{host}}/actuator/prometheus

### Health
GET {{host}}/actuator/health

### Liveness
GET {{host}}/actuator/health/liveness

### Readiness
GET {{host}}/actuator/health/readiness
