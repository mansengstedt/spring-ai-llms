spring:
  config:
    activate:
      on-profile: test
    import: classpath:secret/application-test-external.yml
  application:
    name: spring-ai-llms
  main:
    allow-bean-definition-overriding: true
  datasource:
    driver-class-name: org.h2.Driver
    url: jdbc:h2:mem:llm;Mode=Oracle
    username: llmclient
    password: llmclient

app:
  toggle:
    message-type: false
  models:
    ollama:
      llm-model-name: unknown
      api-connection:
        url: http://localhost:11434
        key: NOT_NEEDED
    openai:
      llm-model-name: openai-latest
      api-connection:
        url: https://api.openai.com
        key: sk-proj-fake-open-ai-key-secret
    anthropic:
      llm-model-name: anthropic-latest
      api-connection:
        url: https://api.anthropic.com
        key: sk-ant-api03-fake-anthropic-key-secret
    docker:
      llm-model-name: unknown
      api-connection:
        url: http://localhost:12434/engines
        key: NOT_NEEDED


---

spring:
  config:
    activate:
      on-profile: wiremock
  ai:
    vertex:
      ai:
        gemini:
          api-endpoint: http://localhost:${wiremock:server:port} #never set so wiremock does not work
          api-key: test-key
          project-id: lithe-breaker-480809-c9
          location: europe-north1

app:
  models:
    ollama:
      api-connection:
        url: http://localhost:${wiremock.server.port}
    docker:
      llm-model-name: unknown
      api-connection:
        url: http://localhost:${wiremock.server.port}
    openai:
      api-connection:
        url: http://localhost:${wiremock.server.port}
    anthropic:
      api-connection:
        url: http://localhost:${wiremock.server.port}


wiremock:
  server:
    stubs: classpath:/wiremock/mappings
