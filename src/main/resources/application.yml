server:
  port: 8999

spring:
  application:
    name: spring-ai-llms
  datasource:
    driver-class-name: oracle.jdbc.OracleDriver
    url: ${ORACLE_SBAB_JDBCURL}
    username: ${DB_USER}
    password: ${DB_PASS}
  liquibase:
    change-log: classpath:db/spring-ai-llms.changelog-master.yaml
    # Default context is needed for the execution of change sets without context
    contexts: default
  jpa:
    open-in-view: false
  threads:
    virtual:
      enabled: true
  jackson:
    serialization:
      WRITE_DATES_AS_TIMESTAMPS: false
      WRITE_DURATIONS_AS_TIMESTAMPS: false
    default-property-inclusion: NON_EMPTY
    deserialization:
      # From tech arch common recommendation
      FAIL_ON_UNKNOWN_PROPERTIES: true
      FAIL_ON_NULL_FOR_PRIMITIVES: true
      FAIL_ON_NUMBERS_FOR_ENUMS: true
      FAIL_ON_READING_DUP_TREE_KEY: true
      FAIL_ON_TRAILING_TOKENS: true
      ACCEPT_FLOAT_AS_INT: false
    property-naming-strategy: SNAKE_CASE
    parser:
      strict-duplicate-detection: true
  #springAi params
  ai:
    anthropic:
      #must be set to dummy value even if not used to avoid errors at startup
      api-key: ${ANTHROPIC_CONNECTION_KEY:NOT_NEEDED}
    openai:
      api-key: ${OPEN_AI_CONNECTION_KEY:NOT_NEEDED}
    chat:
      base-url: ${DOCKER_CONNECTION_URL:http://localhost:12434/engines}
      options:
        model: ${DOCKER_LLM_MODEL_NAME:ai/llama3.2}
    vertex:
      ai:
        gemini:
          project-id: lithe-breaker-480809-c9 #mandatory at startup
          location: europe-north1

app:
  toggle:
    message-type: false
  models:
    ollama:
      llm-model-name: ${OLLAMA_LLM_MODEL_NAME:unknown}
      api-connection:
        url: ${OLLAMA_CONNECTION_URL:http://localhost:11434}
        key: ${OLLAMA_CONNECTION_KEY:NOT_NEEDED}
    openai:
      llm-model-name: ${OPEN_AI_LLM_MODEL_NAME:openai-latest}
      api-connection:
        url: ${OPEN_AI_CONNECTION_URL:https://api.openai.com}
        key: ${OPEN_AI_CONNECTION_KEY} #set in env variable
    anthropic:
      llm-model-name: ${ANTHROPIC_LLM_MODEL_NAME:anthropic-latest}
      api-connection:
        url: ${ANTHROPIC_CONNECTION_URL:https://api.anthropic.com}
        key: ${ANTHROPIC_CONNECTION_KEY} #set in env variable
    docker:
      llm-model-name: ${DOCKER_LLM_MODEL_NAME:unknown}
      api-connection:
        url: ${DOCKER_CONNECTION_URL:http://localhost:12434/engines}
        key: ${DOCKER_CONNECTION_KEY:NOT_NEEDED}
    gemini:
      llm-model-name: ${GEMINI_LLM_MODEL_NAME:gemini-3-pro-preview}
      api-connection:
        url: ${GEMINI_CONNECTION_URL:https://generativelanguage.googleapis.com/v1beta} #not needed, set in the credential file
        key: ${GEMINI_CONNECTION_KEY:NOT_NEEDED} #not needed

logging:
  level:
    org.springframework.ai.chat.client: DEBUG
    org.springframework.ai.chat.client.advisor: DEBUG

management:
  endpoints:
    web:
      exposure:
        include: info,prometheus,health
  info:
    env:
      enabled: true
    java:
      enabled: true
  endpoint:
    health:
      show-details: always
      probes:
        enabled: true
      group:
        liveness:
          include: livenessState
        readiness:
          # This service cannot work without a DB
          include: readinessState

springdoc:
  api-docs:
    path: /api-docs
    enabled: true
    swagger-ui:
      path: /swagger-ui.html
      enabled: true
      operationsSorter: method
      tagsSorter: alpha
      layout: BaseLayout
      disable-swagger-default-url: true
    packagesToScan: com.ment.chat.client.**
    pathsToMatch: /api/**

---

spring:
  config:
    activate:
      on-profile: local-db-oracle
  datasource:
    url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=localhost)(PORT=1521))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=FREEPDB1)))
    username: CONVERSATION_LOCAL
    password: CONVERSATION_LOCAL

---

spring:
  config:
    activate:
      on-profile: local-h2
  datasource:
    driver-class-name: org.h2.Driver
    url: jdbc:h2:mem:testdb;Mode=Oracle
    username: CONVERSATION_LOCAL
    password: CONVERSATION_LOCAL
  h2:
    console:
      enabled: true